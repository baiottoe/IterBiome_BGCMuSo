{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b482542e",
   "metadata": {},
   "source": [
    "# Daymet V4 - Programmatic Data Discovery, Access, Subsetting, and Download for Analysis Ready Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a577b0cc-cb45-4cf6-a77b-01025bd631b3",
   "metadata": {},
   "source": [
    "**Please note that the link to access daymet data used here is subject to change and may need to periodically updated**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50489f29",
   "metadata": {},
   "source": [
    "*Original Author:  ORNL DAAC*\n",
    "<br>\n",
    "*Date: August 31, 2021*\n",
    "<br>\n",
    "*Contact for [ORNL DAAC](https://daac.ornl.gov/):  uso@daac.ornl.gov*\n",
    "<br>\n",
    "*Link to [Original Notebook](https://github.com/ornldaac/daymet-python-opendap-xarray)*\n",
    "<br>\n",
    "*Editor:  Teagan Baiotto*\n",
    "<br>\n",
    "*Last Edited:  January 19, 2023*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffead84",
   "metadata": {},
   "source": [
    "## Daymet Overview\n",
    "**Daymet** provides long-term, continuous, gridded estimates of daily weather and climatology variables by interpolating and extrapolating ground-based observations through statistical modeling techniques. \n",
    "\n",
    "Daily files are produced on a **1km x 1km** spatial grid and distributed in a multidimensional, netCDF, file format. Daymet data is available for continenal North America (na), with Hawaii (hi), and Puerto Rico (pr) as separate data files.\n",
    "\n",
    "DAYMET Temporal Availability:\n",
    "\n",
    "| Spatial Area    | Years                          \n",
    "|:---------       |:---------------------------------------:|\n",
    "| North America   | 1980 - present\n",
    "| Hawaii          | 1980 - 2020\n",
    "| Puerto Rico     | 1950 - 2020\n",
    "\n",
    "DAYMET VARIABLES:\n",
    "\n",
    "| Variable | Description (units)                           \n",
    "|:---------|:---------------------------------------:|\n",
    "| tmax     | Daily maximum 2-meter air temperature (°C)\n",
    "| tmin     | Daily minimum 2-meter air temperature (°C)\n",
    "| prcp     | Daily total precipitation (mm/day)\n",
    "| srad     | Incident shortwave radiation flux density (W/m2)\n",
    "| vp       | Water vapor pressure (Pa)\n",
    "| swe      | Snow water equivalent (kg/m2)\n",
    "| dayl     | Duration of the daylight period (seconds/day)\n",
    "\n",
    "\n",
    "Daymet V4 Daily Data files (or granules) are natively in netCDF4 format, and each file has one year's worth of data. Data files are organized by variables (dayl, prcp, tmin, tmax, srad, swe, vp) and regions (each for na, pr, hi).\n",
    "\n",
    "The standard naming convention for a file is:  \n",
    "\n",
    "- daymet_v4_daily_`area`_`variable`_`year`.nc\n",
    "\n",
    "\n",
    "#### Daymet Data: ORNL DAAC \n",
    "- The [Daymet Website](https://daymet.ornl.gov) provides comprehensive information about and access methods for the Daymet datasets under the [Get Data](https://daymet.ornl.gov/getdata) tab. \n",
    "\n",
    "- Landing Page for [Daymet: Daily Surface Weather Data on a 1-km Grid for North America, Version 4](https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1840).  \n",
    "- Daymet V4 Daily Data dataset DOI **https://doi.org/10.3334/ORNLDAAC/1840**\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Thornton, M.M., R. Shrestha, Y. Wei, P.E. Thornton, S. Kao, and B.E. Wilson. 2020. Daymet: Daily Surface Weather Data on a 1-km Grid for North America, Version 4. ORNL DAAC, Oak Ridge, Tennessee, USA. https://doi.org/10.3334/ORNLDAAC/1840\n",
    "</div>\n",
    "\n",
    "\n",
    "- ORNL DAAC access to Daymet daily data through THREDDS Data Server (TDS) [Daymet V4 Daily Data: THREDDS](https://thredds.daac.ornl.gov/thredds/catalog/ornldaac/1840/catalog.html)\n",
    "\n",
    "#### Daymet Data: NASA Earthdata\n",
    " - [NASA Earthdata Daymet Collections](https://search.earthdata.nasa.gov/portal/ornldaac/search?fpj=Daymet!Daymet!Daymet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460917a8",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a23272",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b> Project Name Setting: </b> Please set the Project Name and Cell Resolution for your project </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde6628-5bdd-49d7-936a-4cb166bdfea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE PROJECT NAME HERE\n",
    "PROJECT_NAME = 'Coweeta'\n",
    "\n",
    "# CURRENT DIRECTORY HERE, SET WHERE THE NOTEBOOKS ARE LOCATED\n",
    "CURRENT_DIRECTORY = ''\n",
    "\n",
    "# SET THE SPATIAL RESOLUTION (in meters)\n",
    "SPATIAL_RESOLUTION = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86dcf03-2f22-478f-ad52-fb7d27b50b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "os.chdir(CURRENT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths as global variables\n",
    "PROJECT_DIR = os.path.join(CURRENT_DIRECTORY, PROJECT_NAME)\n",
    "RAWGIS_DIR = os.path.join(PROJECT_DIR, \"gis_data\")\n",
    "RAWOBS_DIR = os.path.join(PROJECT_DIR, \"obs\")\n",
    "RAWSOIL_DIR = os.path.join(RAWGIS_DIR, \"soil\")\n",
    "MODEL_DIR = os.path.join(PROJECT_DIR, 'model')\n",
    "DEF_DIR = os.path.join(MODEL_DIR, 'defs')\n",
    "INI_DIR = os.path.join(MODEL_DIR, 'ini_files')\n",
    "EPC_DIR = os.path.join(MODEL_DIR, 'epc_files')\n",
    "OUTPUT_DIR = os.path.join(MODEL_DIR, 'output')\n",
    "CO2_DIR = os.path.join(MODEL_DIR, 'co2')\n",
    "NDEP_DIR = os.path.join(MODEL_DIR, 'ndep')\n",
    "ENDPOINT_DIR = os.path.join(MODEL_DIR, 'endpoint_files')\n",
    "SPINUP_DIR = os.path.join(MODEL_DIR, 'spinup')\n",
    "NORMAL_DIR = os.path.join(MODEL_DIR, 'normal')\n",
    "MODEL_RAST_DIR = os.path.join(MODEL_DIR, 'raster_inputs')\n",
    "IMAGE = os.path.join(PROJECT_DIR, 'image_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9d122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install necessary packages. If errors, try un-commenting the other packages and re-running this cell.\n",
    "\n",
    "# !pip install geopandas\n",
    "# !pip install pyproj\n",
    "# !pip install rioxarray\n",
    "# !pip install xarray\n",
    "# !pip install shapely\n",
    "# !pip install descartes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24350611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pyproj\n",
    "from pyproj import CRS, Transformer, Proj, transform\n",
    "import datetime as dt \n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import shapely\n",
    "import rasterio\n",
    "from rasterio.features import Affine\n",
    "import time\n",
    "from shapely.geometry import mapping\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d496fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This Notebook was produced with the following versions\")\n",
    "print(\"geopanda version   : \", gpd.__version__)\n",
    "print(\"pyproj version     : \", pyproj.__version__)\n",
    "print(\"rioxarray version  : \", rioxarray.__version__)\n",
    "print(\"xarray version     : \", xr.__version__)\n",
    "print(\"shapely            : \", shapely.__version__)\n",
    "print(\"rasterio           : \", rasterio.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1706a",
   "metadata": {},
   "source": [
    "## Step 1.  Setting Search and Subset Parameters: Spatial Area of Interest and Time Range of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fe0b9e",
   "metadata": {},
   "source": [
    "We'll use Python's [GeoPandas](https://geopandas.org/index.html) to provide a spatial extent from our AOI shapefile.\n",
    "\n",
    "* **`Geopandas`** is a Python library that enables the use and manipulation of geospatial data. It extends the common datatype used in pandas to allow for many and unique geometric operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd02e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in AOI shapefile\n",
    "aoi = gpd.read_file(os.path.join(RAWGIS_DIR, 'AOI.shp'))\n",
    "aoi = aoi.to_crs(\"EPSG:4326\") # to_crs re-projects to WGS84, if it is not already in that projection\n",
    "# ax = aoi.plot()\n",
    "\n",
    "aoi.crs  # Lists the coordinate reference system (crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16907818",
   "metadata": {},
   "source": [
    "As we see above, the boundary file is in the `WGS 84` projection. Daymet is project to the `lambert_conformal_conic (LCC)` system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a957075d",
   "metadata": {},
   "source": [
    "### Re-project vector file using the **`GeoDataFrame.to_crs`** \n",
    "We'll need bounding box coordinates in 2 reference systems\n",
    "1. **Geographic** - for searching NASA Earthdata metadata\n",
    "2. **Lambert Conformal Conic** - Daymet's crs - for subsetting the file using OPeNDAP protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5900de85",
   "metadata": {},
   "source": [
    "### 1.1 **Geographic** bounding box - for searching NASA Earthdata metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's determine and store the geographic bounding box of the Park boundary for Earthdata Searching\n",
    "# data can be re-projected using the GeoDataFrame.to_crs() command:\n",
    "\n",
    "xy = aoi.bounds # bound of polygon in lat, lon \n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = aoi.bounds.values.tolist()[0] # We'll need the bounding box as a Python list \n",
    "                                              # to server as a subsetting parameter\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dd028a",
   "metadata": {},
   "source": [
    "### 1.2. **Lambert Conformal Conic** bounding box - Daymet's CRS - for subsetting the file using OPeNDAP protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6898c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Daymet proj - we'll use this in a later step\n",
    "daymet_proj = \"+proj=lcc +ellps=WGS84 +a=6378137 +b=6356752.314245 +lat_1=25 +lat_2=60 +lon_0=-100 +lat_0=42.5 +x_0=0 +y_0=0 +units=m +no_defs\"\n",
    "aoi_lcc = aoi.to_crs(daymet_proj) # to_crs re-projects from UTM 17N to LCC\n",
    "lccbounds = aoi_lcc.bounds # Bounds in LCC projection\n",
    "lccbounds.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e0720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot differences in AOI appearance in original and projected coordinate system\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "#grsm_poly.plot(ax=ax1, facecolor='blue');\n",
    "aoi.plot(ax=ax1, facecolor='blue');\n",
    "ax1.set_title(\"AOI Geographic Coordinate System\");\n",
    "aoi_lcc.plot(ax=ax2, facecolor='grey');\n",
    "ax2.set_title(\"AOI Daymet LCC Projection\");\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085cdcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend AOI by 1 km on each side to ensure data is downloaded for full extent\n",
    "x_lower, y_lower, x_upper, y_upper = lccbounds.round(2).values.tolist()[0][0] - 1000, lccbounds.round(2).values.tolist()[0][1] - 1000, lccbounds.round(2).values.tolist()[0][2] + 1000, lccbounds.round(2).values.tolist()[0][3] + 1000\n",
    "lccbounds.minx[0], lccbounds.miny[0], lccbounds.maxx[0], lccbounds.maxy[0] = x_lower, y_lower, x_upper, y_upper\n",
    "lccbounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67bed4f",
   "metadata": {},
   "source": [
    "### 1.3. Let's also define a `time range` in a format that the API recognizes, and the Daymet `variables` of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d694022",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b> Project Dates: </b> Please set start and end date for model simulation </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e14b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date format = (YYYY, MM, DD)\n",
    "start_date = dt.datetime(1980, 1, 1) # specify your own start date\n",
    "end_date = dt.datetime(2022, 12, 31)  # specify your end start date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c773ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_format = '%Y-%m-%dT%H:%M:%SZ' # format requirement for datetime search\n",
    "temporal_str = start_date.strftime(dt_format) + ',' + end_date.strftime(dt_format)\n",
    "\n",
    "variables = ['prcp', 'tmax', 'tmin', 'dayl', 'srad', 'vp'] # select a Daymet variable of interest\n",
    "print(temporal_str)\n",
    "print(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3388dc7",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f69c02",
   "metadata": {},
   "source": [
    "## Step 2. Leveraging NASA's Common Metadata Repository (CMR) API to search for Daymet data within a spatial and temporal region of interest\n",
    "\n",
    "##### Now that we've defined our spatial and temporal area-of-interest, we'll see how we can programatically use those as a search parameters to discover Daymet V4 Daily data.  \n",
    "\n",
    "##### At the end of this step, we will have a list of Daymet files that are within our search criteria (bounding box and time period)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ff659",
   "metadata": {},
   "source": [
    "#### A little background ...\n",
    "\n",
    "- Searching [NASA's Earthdata Holdings](https://search.earthdata.nasa.gov/search) can lead to quite a few files for a user to consider. \n",
    "![title](images/InkedNASAEarthdataCollectionSearch_narrow_LI.jpg)\n",
    "<br>\n",
    "\n",
    "Some helpful background:\n",
    "- NASA has a metadata system that catalogs all data and metadata records:  [Common Metadata Repository (CMR)](https://earthdata.nasa.gov/eosdis/science-system-description/eosdis-components/cmr) \n",
    "\n",
    "- Using the [CMR API](https://cmr.earthdata.nasa.gov/search), we can search metadata records to discovered data granules (files).\n",
    "\n",
    "\n",
    "**`Request URL's`**\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "https://cmr.earthdata.nasa.gov/search/collections\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "https://cmr.earthdata.nasa.gov/search/granules\n",
    "</div>\n",
    "\n",
    "- The [Daymet V4 Daily](https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1840) data DOI, **`doi.org/10.3334/ORNLDAAC/1840`**.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a382f912",
   "metadata": {},
   "source": [
    "### 2.1. Searching NASA's Earthdata Collections for Daymet V4 Daily Data \"`Concept ID`\"\n",
    "\n",
    "#### The **`Concept ID`** is a NASA Earthdata unique ID for **Dataset Collections**.  We'll see how to programatically obtain the Concept ID below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0839dc75",
   "metadata": {},
   "source": [
    "Using Python's **`requests`** library, we will build and provide an HTTP request to search **`NASA's Earthdata Collections`** for Daymet V4 Daily Dataset Collection to acquire the **`concept_id`** unique to the Daymet V4 Daily data in NASA's Earthdata holdings.  \n",
    "\n",
    "* **`requests`** is a simple HTTP libray for Python.  It allows you to easily send HTTP requests.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "https://cmr.earthdata.nasa.gov/search/collections\n",
    "</div>\n",
    "\n",
    "To build the URL Request we'll use:\n",
    "- the CMR Request URL\n",
    "- Daymet V4 Daily Data DOI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "daymet_doi = '10.3334/ORNLDAAC/2129' # define the Daymet V4 Daily Data DOI as the variable `daymet_doi`. UPDATE THIS IF NOT WORKING\n",
    "cmrurl='https://cmr.earthdata.nasa.gov/search/' # define the base url of NASA's CMR API as the variable `cmrurl`\n",
    "doisearch = cmrurl + 'collections.json?doi=' + daymet_doi # Create the Earthdata Collections URL\n",
    "print('Earthdata Collections URL: Daymet V4 Daily -->', doisearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the doisearch, we can obtain the ConceptID for the Daymet V4 Daily data\n",
    "# We'll search the json response of the Daymet metadata for \"id\" within the 'entry' dictionary key\n",
    "response = requests.get(doisearch)\n",
    "collection = response.json()['feed']['entry'][0] \n",
    "#print(collection)\n",
    "concept_id = collection['id']\n",
    "print('NASA Earthdata Concept_ID --> ' , concept_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2086317c",
   "metadata": {},
   "source": [
    "`C2031536952-ORNL_CLOUD` is the unique NASA-given Concept ID for the Daymet V4 Daily data Collection. We'll use this to search for Daymet V4 Daily files (granules) that match our search criteria. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18731a4",
   "metadata": {},
   "source": [
    "### 2.2. Searching NASA's Earthdata Holdings for Daymet `Granules` (Files)\n",
    "#### Now that we have all our parameters defined, let's search NASA's Earthdata Granules for all the data that are within those search criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40150c4d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "https://cmr.earthdata.nasa.gov/search/granules\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d50640",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variables we have defined to pass to the CMR API')\n",
    "print('-----------------------------------------------')\n",
    "print('time range      :', temporal_str)\n",
    "print('Daymet variables :', variables)\n",
    "print('bounding box    :')\n",
    "print(xy)\n",
    "print('concept ID      :', concept_id)\n",
    "print('cmr url         :', cmrurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c601f8",
   "metadata": {},
   "source": [
    "### 2.2.a. We'll build a Request URL `granulesearch` to create a listing of all the granules (files) in NASA's Earthdata holdings that fit the search criteria we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "granulesearch = cmrurl + 'granules.json?collection_concept_id=' + concept_id + \\\n",
    "                '&page_size=1000' + '&temporal=' + temporal_str + \\\n",
    "                '&bounding_box[]=' + ','.join(map(str, xy))\n",
    "print(granulesearch)                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a02f914",
   "metadata": {},
   "source": [
    "### 2.2.b. Again using Python's **`requests`** library, we can provide the URL `granulesearch` to create a listing of all the granules (files) in **NASA's Earthdata** holdings that fit the search criteria we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb30dcca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create list of granules we want\n",
    "\n",
    "response = requests.get(granulesearch)\n",
    "granules = response.json()['feed']['entry'] \n",
    "granule_names = {}  # create an empty array\n",
    "for var in variables:\n",
    "    granule_names[var] = []\n",
    "    \n",
    "for g in granules:\n",
    "    granule_name = g['title'] # fill the array with granule names that match our search parameters\n",
    "    for var in granule_names.keys():\n",
    "        if var in granule_name:\n",
    "            granule_names[var].append(granule_name)\n",
    "            print(granule_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e2a1d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f08124e",
   "metadata": {},
   "source": [
    "## Step 3. Downloading subset data through ORNL DAAC THREDDS Data Server\n",
    "Daymet V4 Daily data is available through ORNL DAAC's THREDDS Data Server. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5edf7",
   "metadata": {},
   "source": [
    "[Daymet V4 Daily Data in the ORNL DAAC THREDDS Data Server](https://thredds.daac.ornl.gov/thredds/catalog/ornldaac/1840/catalog.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74962e",
   "metadata": {},
   "source": [
    "### 3.1. **`OPeNDAP`** allows users to use data files that are stored on remote computers with their favorite analysis and visualization client software.\n",
    "\n",
    "NASA Earthdata has great informaion on OPeNDAP: [What is OPeNDAP](https://earthdata.nasa.gov/collaborate/open-data-services-and-software/api/opendap)\n",
    "\n",
    "### 3.1.a. We'll use Pythons **`netCDF4`** library\n",
    "* connect to OPeNDAP service and subset data \n",
    "\n",
    "### 3.1.b. We'll use Python's **`Xarray`** Library to \n",
    "* open the data files we are searching for, \n",
    "* subset the North American file based on the Lambert Conformal Conic **`lccbounds`** bounding box we defined earlier, \n",
    "* concatenate the time range of files into one file, and \n",
    "* save the concatened file to a netCDF file.\n",
    "\n",
    "netCDF4\n",
    "* **Dataset**\n",
    "\n",
    "Xarray\n",
    "* **open_dataset** \n",
    "* **slice**\n",
    "* **concat**\n",
    "* **to_netcdf**\n",
    "\n",
    "We will subset and download Daymet V4 Daily Data based on\n",
    "- **`granual_names`** array we saved above \n",
    "- our polygonal region of interest (LCC bounding box)\n",
    "- our time range of interest\n",
    "- Daymet variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc51ff",
   "metadata": {},
   "source": [
    "**Note:** The beginning of the **`granule_names`** filename (**\"Daymet_Daily_V4.\"**) is specific to the Earthdata naming convention.  We'll strip out (**\"Daymet_Daily_V4.\"**) below when we access the files from the on-prem ORNL DAAC's OPeNDAP client through THREDDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f747cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "# specify an url, the JARKUS dataset in this case\n",
    "thredds_url = 'https://thredds.daac.ornl.gov/thredds/dodsC/ornldaac/2129/' # ORNL DAAC TDS OPeNDAP URL \n",
    "                                                                           # for Daymet V4 Daily Files\n",
    "before = time.time()\n",
    "    \n",
    "def var_retrieval(var):\n",
    "    cnt = 0\n",
    "    for g_name in granule_names[var]:\n",
    "        print(' ***GRANULE_NAME*** ---->', g_name)\n",
    "        granule_dap = thredds_url + g_name.replace('Daymet_Daily_V4R1.','')\n",
    "        print(granule_dap)\n",
    "\n",
    "        # Using netcdf's dataset \n",
    "        thredds_ds = Dataset(granule_dap)\n",
    "\n",
    "        ds = xr.open_dataset(xr.backends.NetCDF4DataStore(thredds_ds), decode_coords=\"all\")\n",
    "\n",
    "        temp=ds[var].sel(x=slice(lccbounds.minx[0],lccbounds.maxx[0]), y=slice(lccbounds.maxy[0],lccbounds.miny[0]))\n",
    "\n",
    "        if cnt==0:\n",
    "            var_data = temp\n",
    "        else:\n",
    "            var_data = xr.concat([var_data, temp], dim=\"time\")\n",
    "\n",
    "        cnt += 1\n",
    "        \n",
    "    var_data.to_netcdf(os.path.join(MODEL_DIR, 'met_data', f'{var}.nc'))\n",
    "\n",
    "pool = multiprocessing.Pool(processes=10)\n",
    "pool.map(var_retrieval, variables)\n",
    "\n",
    "print(\"Processing Time: \", time.time() - before, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e95cbff",
   "metadata": {},
   "source": [
    "### 3.1.c.  Combine Individual Data Arrays into Xarray.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfd596",
   "metadata": {},
   "source": [
    "Each data variable was downloaded seperately, so we will need to now combine them for easier use later. The python module **Xarray** has a merge function which allows multiple datasets with the same coordinates/dimensions but different variables to be combined together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c472206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for var in variables:\n",
    "    if count == 0:\n",
    "        combined = xr.open_dataset(os.path.join(MODEL_DIR, 'met_data', f'{var}.nc'))\n",
    "    else:\n",
    "        combined = xr.merge([combined, xr.open_dataset(os.path.join(MODEL_DIR, 'met_data', f'{var}.nc'))])\n",
    "    count += 1\n",
    "\n",
    "display(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62c55c",
   "metadata": {},
   "source": [
    "### 3.2 Visualize Daymet Tmin Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6061a8",
   "metadata": {},
   "source": [
    "Create a map of one array of data contained within the data downloaded above. Doing so allows for a superficial check to make sure everything downloaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb437875",
   "metadata": {},
   "outputs": [],
   "source": [
    "prcp_grsm = combined['tmin'].isel(time=10) # isel = xarray index selection (python index start from 0, so time is Jan 7, 2010)\n",
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "prcp_grsm.plot(ax=ax, robust=True, cbar_kwargs={'label': 'degrees C'})\n",
    "aoi.plot(ax = ax, color = 'none', edgecolor = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f8376",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d2a1e",
   "metadata": {},
   "source": [
    "### 3.3 Save to Netcdf in Model Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd66e09",
   "metadata": {},
   "source": [
    "Save the Daymet meteorological data as a netcdf to be opened in next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd52b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_netcdf(os.path.join(MODEL_DIR, 'met_data', 'aoi_met.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0309f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
